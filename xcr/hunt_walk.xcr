# submit multiple jobs by using Xcrypt

# Xcrypt specific settings
use base qw(limit core);
use File::Copy;
limit::initialize(2);# limitation on Aquarius

# global settings
$id_name = "hunt_walk";
$num_trials = 1;

# usage of Aquarius
$num_nodes = 1;

# configuration of Aquarius
$GPUs_per_node = 8;
$GPUs_per_socket = 4;


# list up compiled binaries
my $bin = "bin";
my @target = glob('bin/tot*');
$num_target = scalar @target;

# # confirmation
# for(local $i = 0; $i <= $#target; $i++){
# 	print "$target[$i]\n";
# }
# print "$num_target binaries\n";

# count number of job-packets
$num_procs = $num_nodes * $GPUs_per_node;
$num_pools = (1 + int(($num_target - 1) / $num_procs));
# print "$num_pools submissions\n";

# prepare to duplicate outputs
my $series = "m31";
for(local $i = 0; $i < $num_procs; $i++){
    # cp dat/m31.* -> dat/m31_$i.*
    copy(sprintf("dat/%s.run.dat", $series), sprintf("dat/%s_%d.run.dat", $series, $i));
    copy(sprintf("dat/%s.cfg.dat", $series), sprintf("dat/%s_%d.cfg.dat", $series, $i));
    copy(sprintf("dat/%s.tmp0.h5", $series), sprintf("dat/%s_%d.tmp0.h5", $series, $i));
}

# split EXEC list
local $full_list = "EXEC_ALL";
open(OUT, ">$full_list") or die "$!";
for(local $i = 0; $i < $num_target; $i++){
	print OUT "$target[$i]\n";
}
close(OUT);
my $part_list = "EXEC_SUB";
my $digits = 5;
`split -d -l $num_procs --suffix-length=$digits $full_list $part_list`;
unlink $full_list;


# Xcrypt specific settings
%template = (
	'id' => "$id_name",
	'RANGE0' => [0..$num_pools-1],
	'RANGE1' => [0..$num_trials-1],

	# commands executed on compute node
	# module settings
	'exe0' => 'module purge',
	'exe1' => 'module load cuda gcc ompi-cuda',
	'exe2' => 'export MODULEPATH=/work/gr16/share/modules/lib:$MODULEPATH',
	'exe3' => 'module load phdf5 cub',
	'exe4' => 'module list',
	# job execution
	'exe5'    => 'mpiexec sh/wisteria/split_hunt_walk.sh',
	'arg5_0@' => sub{"--wrapper-Nprocs_node=$GPUs_per_node"},
	'arg5_1@' => sub{"--wrapper-Nprocs_socket=$GPUs_per_socket"},
    'arg5_2@' => sub{"--wrapper-EXEC-list=$part_list"},
    'arg5_3@' => sub{"--wrapper-packetID=$VALUE[0]"},
	'arg5_4@' => sub{"--wrapper-digits=$digits"},
	'arg5_5'  => '-absErr=1.953125000e-3',
	'arg5_6@' => sub{"--wrapper-series=$series"},
	'arg5_7'  => '--wrapper-logdir=log',
	# 'arg5_0@' => sub{"$bin/$target[$VALUE[0]]"},
	# 'arg5_3@' => sub{"-jobID=$VALUE[0]"},
	# 'arg5_4@' => sub{"1>>log/$target[$VALUE[0]]_$VALUE[0].log"},
	# 'arg5_5@' => sub{"2>>log/$target[$VALUE[0]]_$VALUE[0].err"},

	# commands executed before job submission
	'before' => sub{
		print "launch $self->{id}\n";
	},
	'after' => sub{
		print "finish $self->{id}\n";
	},

	# settings for job script
	'JS_queue' => 'short-a',
	'JS_phnode@' => sub{"$num_nodes"},# number of nodes
	'JS_node@' => sub{"$num_procs"},# number of MPI processes
	'JS_limit_time' => '00:03:00'
);
prepare_submit_sync(%template);
